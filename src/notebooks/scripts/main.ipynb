{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd1de9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import f_oneway, kruskal\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3e4812d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848aff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SolarDataAnalyzer:\n",
    "    \"\"\"Comprehensive solar data analysis for MoonLight Energy Solutions\"\"\"\n",
    "    \n",
    "    def __init__(self, filepath, country_name):\n",
    "        \"\"\"Initialize with data file path and country name\"\"\"\n",
    "        self.country = country_name\n",
    "        self.df = pd.read_csv(filepath)\n",
    "        self.df_clean = None\n",
    "        \n",
    "    def initial_profiling(self):\n",
    "        \"\"\"Generate initial data profiling report\"\"\"\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"INITIAL DATA PROFILE - {self.country.upper()}\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        # Basic info\n",
    "        print(f\"Dataset Shape: {self.df.shape}\")\n",
    "        print(f\"Date Range: {self.df['Timestamp'].min()} to {self.df['Timestamp'].max()}\\n\")\n",
    "        \n",
    "        # Missing values report\n",
    "        print(\"MISSING VALUES REPORT\")\n",
    "        print(\"-\" * 60)\n",
    "        missing = self.df.isna().sum()\n",
    "        missing_pct = (missing / len(self.df)) * 100\n",
    "        missing_df = pd.DataFrame({\n",
    "            'Missing_Count': missing,\n",
    "            'Percentage': missing_pct\n",
    "        })\n",
    "        missing_df = missing_df[missing_df['Missing_Count'] > 0].sort_values('Percentage', ascending=False)\n",
    "        print(missing_df)\n",
    "        \n",
    "        # Columns with >5% nulls\n",
    "        critical_missing = missing_df[missing_df['Percentage'] > 5]\n",
    "        if len(critical_missing) > 0:\n",
    "            print(f\"\\n⚠️  CRITICAL: {len(critical_missing)} columns have >5% missing values\")\n",
    "            print(critical_missing)\n",
    "        else:\n",
    "            print(\"\\n✓ No columns have >5% missing values\")\n",
    "        \n",
    "        # Summary statistics\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"SUMMARY STATISTICS\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        numeric_cols = self.df.select_dtypes(include=[np.number]).columns\n",
    "        print(self.df[numeric_cols].describe())\n",
    "        \n",
    "        return missing_df\n",
    "    \n",
    "    def detect_outliers(self, columns=None):\n",
    "        \"\"\"Detect outliers using Z-score method (|Z| > 3)\"\"\"\n",
    "        if columns is None:\n",
    "            columns = ['GHI', 'DNI', 'DHI', 'ModA', 'ModB', 'WS', 'WSgust']\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"OUTLIER DETECTION (Z-score method, |Z| > 3)\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        outlier_summary = {}\n",
    "        for col in columns:\n",
    "            if col in self.df.columns:\n",
    "                z_scores = np.abs(stats.zscore(self.df[col].dropna()))\n",
    "                outliers = (z_scores > 3).sum()\n",
    "                outlier_pct = (outliers / len(self.df)) * 100\n",
    "                outlier_summary[col] = {\n",
    "                    'count': outliers,\n",
    "                    'percentage': outlier_pct\n",
    "                }\n",
    "                print(f\"{col:15} : {outliers:5} outliers ({outlier_pct:.2f}%)\")\n",
    "        \n",
    "        return outlier_summary\n",
    "    \n",
    "    def clean_data(self, strategy='median'):\n",
    "        \"\"\"Clean data by handling missing values and outliers\"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"DATA CLEANING\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        self.df_clean = self.df.copy()\n",
    "        \n",
    "        # Convert timestamp\n",
    "        self.df_clean['Timestamp'] = pd.to_datetime(self.df_clean['Timestamp'])\n",
    "        \n",
    "        # Key columns for imputation\n",
    "        key_columns = ['GHI', 'DNI', 'DHI', 'ModA', 'ModB', 'Tamb', 'RH', 'WS', 'BP']\n",
    "        \n",
    "        # Impute missing values\n",
    "        for col in key_columns:\n",
    "            if col in self.df_clean.columns:\n",
    "                missing_before = self.df_clean[col].isna().sum()\n",
    "                if missing_before > 0:\n",
    "                    if strategy == 'median':\n",
    "                        self.df_clean[col].fillna(self.df_clean[col].median(), inplace=True)\n",
    "                    elif strategy == 'mean':\n",
    "                        self.df_clean[col].fillna(self.df_clean[col].mean(), inplace=True)\n",
    "                    print(f\"✓ Imputed {missing_before} missing values in {col}\")\n",
    "        \n",
    "        # Handle negative values in irradiance (physically impossible)\n",
    "        irradiance_cols = ['GHI', 'DNI', 'DHI', 'ModA', 'ModB']\n",
    "        for col in irradiance_cols:\n",
    "            if col in self.df_clean.columns:\n",
    "                neg_count = (self.df_clean[col] < 0).sum()\n",
    "                if neg_count > 0:\n",
    "                    self.df_clean.loc[self.df_clean[col] < 0, col] = 0\n",
    "                    print(f\"✓ Corrected {neg_count} negative values in {col}\")\n",
    "        \n",
    "        print(f\"\\n✓ Cleaned dataset shape: {self.df_clean.shape}\")\n",
    "        return self.df_clean\n",
    "    \n",
    "    def time_series_analysis(self):\n",
    "        \"\"\"Analyze time series patterns\"\"\"\n",
    "        if self.df_clean is None:\n",
    "            print(\"⚠️  Please run clean_data() first\")\n",
    "            return\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "        fig.suptitle(f'Time Series Analysis - {self.country}', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # Extract time features\n",
    "        self.df_clean['Hour'] = self.df_clean['Timestamp'].dt.hour\n",
    "        self.df_clean['Month'] = self.df_clean['Timestamp'].dt.month\n",
    "        self.df_clean['Date'] = self.df_clean['Timestamp'].dt.date\n",
    "        \n",
    "        # Daily pattern - GHI\n",
    "        hourly_ghi = self.df_clean.groupby('Hour')['GHI'].mean()\n",
    "        axes[0, 0].plot(hourly_ghi.index, hourly_ghi.values, marker='o', linewidth=2)\n",
    "        axes[0, 0].set_title('Average GHI by Hour of Day', fontweight='bold')\n",
    "        axes[0, 0].set_xlabel('Hour')\n",
    "        axes[0, 0].set_ylabel('GHI (W/m²)')\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Monthly pattern - GHI, DNI, DHI\n",
    "        monthly_data = self.df_clean.groupby('Month')[['GHI', 'DNI', 'DHI']].mean()\n",
    "        monthly_data.plot(ax=axes[0, 1], marker='o', linewidth=2)\n",
    "        axes[0, 1].set_title('Monthly Average Irradiance', fontweight='bold')\n",
    "        axes[0, 1].set_xlabel('Month')\n",
    "        axes[0, 1].set_ylabel('Irradiance (W/m²)')\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Temperature vs Time\n",
    "        hourly_temp = self.df_clean.groupby('Hour')['Tamb'].mean()\n",
    "        axes[1, 0].plot(hourly_temp.index, hourly_temp.values, marker='o', \n",
    "                       color='orangered', linewidth=2)\n",
    "        axes[1, 0].set_title('Average Temperature by Hour', fontweight='bold')\n",
    "        axes[1, 0].set_xlabel('Hour')\n",
    "        axes[1, 0].set_ylabel('Temperature (°C)')\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Daily trends\n",
    "        daily_ghi = self.df_clean.groupby('Date')['GHI'].mean()\n",
    "        axes[1, 1].plot(daily_ghi.index, daily_ghi.values, linewidth=1, alpha=0.7)\n",
    "        axes[1, 1].set_title('Daily Average GHI Trend', fontweight='bold')\n",
    "        axes[1, 1].set_xlabel('Date')\n",
    "        axes[1, 1].set_ylabel('GHI (W/m²)')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def cleaning_impact_analysis(self):\n",
    "        \"\"\"Analyze impact of cleaning on module performance\"\"\"\n",
    "        if self.df_clean is None or 'Cleaning' not in self.df_clean.columns:\n",
    "            print(\"⚠️  Cleaning data not available\")\n",
    "            return\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        fig.suptitle(f'Cleaning Impact Analysis - {self.country}', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        cleaning_impact = self.df_clean.groupby('Cleaning')[['ModA', 'ModB']].mean()\n",
    "        \n",
    "        # ModA\n",
    "        cleaning_impact['ModA'].plot(kind='bar', ax=axes[0], color=['coral', 'lightblue'])\n",
    "        axes[0].set_title('ModA Performance: Pre vs Post Cleaning', fontweight='bold')\n",
    "        axes[0].set_xlabel('Cleaning Status (0=Before, 1=After)')\n",
    "        axes[0].set_ylabel('Average ModA (W/m²)')\n",
    "        axes[0].set_xticklabels(['Before Cleaning', 'After Cleaning'], rotation=0)\n",
    "        \n",
    "        # ModB\n",
    "        cleaning_impact['ModB'].plot(kind='bar', ax=axes[1], color=['coral', 'lightblue'])\n",
    "        axes[1].set_title('ModB Performance: Pre vs Post Cleaning', fontweight='bold')\n",
    "        axes[1].set_xlabel('Cleaning Status (0=Before, 1=After)')\n",
    "        axes[1].set_ylabel('Average ModB (W/m²)')\n",
    "        axes[1].set_xticklabels(['Before Cleaning', 'After Cleaning'], rotation=0)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print statistics\n",
    "        print(\"\\nCleaning Impact Statistics:\")\n",
    "        print(cleaning_impact)\n",
    "        \n",
    "        if len(cleaning_impact) > 1:\n",
    "            improvement_a = ((cleaning_impact.loc[1, 'ModA'] - cleaning_impact.loc[0, 'ModA']) \n",
    "                           / cleaning_impact.loc[0, 'ModA'] * 100)\n",
    "            improvement_b = ((cleaning_impact.loc[1, 'ModB'] - cleaning_impact.loc[0, 'ModB']) \n",
    "                           / cleaning_impact.loc[0, 'ModB'] * 100)\n",
    "            print(f\"\\n✓ ModA improvement after cleaning: {improvement_a:.2f}%\")\n",
    "            print(f\"✓ ModB improvement after cleaning: {improvement_b:.2f}%\")\n",
    "    \n",
    "    def correlation_analysis(self):\n",
    "        \"\"\"Analyze correlations between variables\"\"\"\n",
    "        if self.df_clean is None:\n",
    "            print(\"⚠️  Please run clean_data() first\")\n",
    "            return\n",
    "        \n",
    "        # Select relevant columns\n",
    "        corr_cols = ['GHI', 'DNI', 'DHI', 'TModA', 'TModB', 'Tamb', 'RH', 'WS', 'BP']\n",
    "        corr_cols = [col for col in corr_cols if col in self.df_clean.columns]\n",
    "        \n",
    "        # Correlation heatmap\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        correlation_matrix = self.df_clean[corr_cols].corr()\n",
    "        sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "                   center=0, square=True, linewidths=1)\n",
    "        plt.title(f'Correlation Matrix - {self.country}', fontsize=16, fontweight='bold', pad=20)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Scatter plots\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "        fig.suptitle(f'Relationship Analysis - {self.country}', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # WS vs GHI\n",
    "        axes[0, 0].scatter(self.df_clean['WS'], self.df_clean['GHI'], alpha=0.3, s=10)\n",
    "        axes[0, 0].set_xlabel('Wind Speed (m/s)')\n",
    "        axes[0, 0].set_ylabel('GHI (W/m²)')\n",
    "        axes[0, 0].set_title('Wind Speed vs GHI')\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # RH vs Tamb\n",
    "        axes[0, 1].scatter(self.df_clean['RH'], self.df_clean['Tamb'], alpha=0.3, s=10, color='green')\n",
    "        axes[0, 1].set_xlabel('Relative Humidity (%)')\n",
    "        axes[0, 1].set_ylabel('Temperature (°C)')\n",
    "        axes[0, 1].set_title('Relative Humidity vs Temperature')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # RH vs GHI\n",
    "        axes[1, 0].scatter(self.df_clean['RH'], self.df_clean['GHI'], alpha=0.3, s=10, color='orange')\n",
    "        axes[1, 0].set_xlabel('Relative Humidity (%)')\n",
    "        axes[1, 0].set_ylabel('GHI (W/m²)')\n",
    "        axes[1, 0].set_title('Relative Humidity vs GHI')\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # DNI vs DHI\n",
    "        axes[1, 1].scatter(self.df_clean['DNI'], self.df_clean['DHI'], alpha=0.3, s=10, color='purple')\n",
    "        axes[1, 1].set_xlabel('DNI (W/m²)')\n",
    "        axes[1, 1].set_ylabel('DHI (W/m²)')\n",
    "        axes[1, 1].set_title('Direct vs Diffuse Irradiance')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def wind_analysis(self):\n",
    "        \"\"\"Analyze wind patterns\"\"\"\n",
    "        if self.df_clean is None:\n",
    "            print(\"⚠️  Please run clean_data() first\")\n",
    "            return\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        fig.suptitle(f'Wind Analysis - {self.country}', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # Wind speed histogram\n",
    "        axes[0].hist(self.df_clean['WS'], bins=50, edgecolor='black', alpha=0.7, color='skyblue')\n",
    "        axes[0].set_xlabel('Wind Speed (m/s)')\n",
    "        axes[0].set_ylabel('Frequency')\n",
    "        axes[0].set_title('Wind Speed Distribution')\n",
    "        axes[0].axvline(self.df_clean['WS'].mean(), color='red', \n",
    "                       linestyle='--', label=f'Mean: {self.df_clean[\"WS\"].mean():.2f} m/s')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Wind direction polar plot (simplified)\n",
    "        if 'WD' in self.df_clean.columns:\n",
    "            # Bin wind directions\n",
    "            wind_bins = np.arange(0, 361, 30)\n",
    "            wd_binned = pd.cut(self.df_clean['WD'], bins=wind_bins)\n",
    "            wd_counts = wd_binned.value_counts().sort_index()\n",
    "            \n",
    "            angles = np.arange(15, 361, 30) * np.pi / 180\n",
    "            axes[1].bar(angles, wd_counts.values, width=0.5, alpha=0.7, color='lightcoral')\n",
    "            axes[1].set_theta_zero_location('N')\n",
    "            axes[1].set_theta_direction(-1)\n",
    "            axes[1].set_title('Wind Direction Distribution')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def distribution_analysis(self):\n",
    "        \"\"\"Analyze distributions of key variables\"\"\"\n",
    "        if self.df_clean is None:\n",
    "            print(\"⚠️  Please run clean_data() first\")\n",
    "            return\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "        fig.suptitle(f'Distribution Analysis - {self.country}', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # GHI histogram\n",
    "        axes[0, 0].hist(self.df_clean['GHI'], bins=50, edgecolor='black', alpha=0.7, color='gold')\n",
    "        axes[0, 0].set_xlabel('GHI (W/m²)')\n",
    "        axes[0, 0].set_ylabel('Frequency')\n",
    "        axes[0, 0].set_title('GHI Distribution')\n",
    "        axes[0, 0].axvline(self.df_clean['GHI'].mean(), color='red', \n",
    "                          linestyle='--', label=f'Mean: {self.df_clean[\"GHI\"].mean():.2f}')\n",
    "        axes[0, 0].legend()\n",
    "        \n",
    "        # DNI histogram\n",
    "        axes[0, 1].hist(self.df_clean['DNI'], bins=50, edgecolor='black', alpha=0.7, color='orange')\n",
    "        axes[0, 1].set_xlabel('DNI (W/m²)')\n",
    "        axes[0, 1].set_ylabel('Frequency')\n",
    "        axes[0, 1].set_title('DNI Distribution')\n",
    "        axes[0, 1].axvline(self.df_clean['DNI'].mean(), color='red', \n",
    "                          linestyle='--', label=f'Mean: {self.df_clean[\"DNI\"].mean():.2f}')\n",
    "        axes[0, 1].legend()\n",
    "        \n",
    "        # Temperature histogram\n",
    "        axes[1, 0].hist(self.df_clean['Tamb'], bins=50, edgecolor='black', alpha=0.7, color='coral')\n",
    "        axes[1, 0].set_xlabel('Temperature (°C)')\n",
    "        axes[1, 0].set_ylabel('Frequency')\n",
    "        axes[1, 0].set_title('Temperature Distribution')\n",
    "        axes[1, 0].axvline(self.df_clean['Tamb'].mean(), color='red', \n",
    "                          linestyle='--', label=f'Mean: {self.df_clean[\"Tamb\"].mean():.2f}')\n",
    "        axes[1, 0].legend()\n",
    "        \n",
    "        # Relative Humidity histogram\n",
    "        axes[1, 1].hist(self.df_clean['RH'], bins=50, edgecolor='black', alpha=0.7, color='lightblue')\n",
    "        axes[1, 1].set_xlabel('Relative Humidity (%)')\n",
    "        axes[1, 1].set_ylabel('Frequency')\n",
    "        axes[1, 1].set_title('Relative Humidity Distribution')\n",
    "        axes[1, 1].axvline(self.df_clean['RH'].mean(), color='red', \n",
    "                          linestyle='--', label=f'Mean: {self.df_clean[\"RH\"].mean():.2f}')\n",
    "        axes[1, 1].legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def temperature_humidity_analysis(self):\n",
    "        \"\"\"Analyze relationship between temperature, humidity and solar radiation\"\"\"\n",
    "        if self.df_clean is None:\n",
    "            print(\"⚠️  Please run clean_data() first\")\n",
    "            return\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        fig.suptitle(f'Temperature & Humidity Analysis - {self.country}', \n",
    "                    fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # Create humidity bins\n",
    "        self.df_clean['RH_bin'] = pd.cut(self.df_clean['RH'], bins=5)\n",
    "        \n",
    "        # Temperature by humidity bins\n",
    "        rh_temp = self.df_clean.groupby('RH_bin')['Tamb'].mean()\n",
    "        rh_temp.plot(kind='bar', ax=axes[0], color='teal', alpha=0.7)\n",
    "        axes[0].set_title('Average Temperature by Humidity Level')\n",
    "        axes[0].set_xlabel('Relative Humidity Range (%)')\n",
    "        axes[0].set_ylabel('Temperature (°C)')\n",
    "        axes[0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # GHI by humidity bins\n",
    "        rh_ghi = self.df_clean.groupby('RH_bin')['GHI'].mean()\n",
    "        rh_ghi.plot(kind='bar', ax=axes[1], color='orange', alpha=0.7)\n",
    "        axes[1].set_title('Average GHI by Humidity Level')\n",
    "        axes[1].set_xlabel('Relative Humidity Range (%)')\n",
    "        axes[1].set_ylabel('GHI (W/m²)')\n",
    "        axes[1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def bubble_chart(self):\n",
    "        \"\"\"Create bubble chart: GHI vs Tamb with RH as bubble size\"\"\"\n",
    "        if self.df_clean is None:\n",
    "            print(\"⚠️  Please run clean_data() first\")\n",
    "            return\n",
    "        \n",
    "        # Sample data for better visualization\n",
    "        sample_data = self.df_clean.sample(min(1000, len(self.df_clean)))\n",
    "        \n",
    "        plt.figure(figsize=(12, 7))\n",
    "        scatter = plt.scatter(sample_data['Tamb'], sample_data['GHI'], \n",
    "                            s=sample_data['RH']*2, alpha=0.5, \n",
    "                            c=sample_data['RH'], cmap='viridis', edgecolors='black', linewidth=0.5)\n",
    "        \n",
    "        plt.colorbar(scatter, label='Relative Humidity (%)')\n",
    "        plt.xlabel('Ambient Temperature (°C)', fontsize=12)\n",
    "        plt.ylabel('GHI (W/m²)', fontsize=12)\n",
    "        plt.title(f'GHI vs Temperature (Bubble Size = Relative Humidity) - {self.country}', \n",
    "                 fontsize=14, fontweight='bold', pad=20)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def export_cleaned_data(self, output_path):\n",
    "        \"\"\"Export cleaned data to CSV\"\"\"\n",
    "        if self.df_clean is None:\n",
    "            print(\"⚠️  Please run clean_data() first\")\n",
    "            return\n",
    "        \n",
    "        self.df_clean.to_csv(output_path, index=False)\n",
    "        print(f\"✓ Cleaned data exported to: {output_path}\")\n",
    "    \n",
    "    def generate_insights_report(self):\n",
    "        \"\"\"Generate key insights for strategic recommendations\"\"\"\n",
    "        if self.df_clean is None:\n",
    "            print(\"⚠️  Please run clean_data() first\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"KEY INSIGHTS REPORT - {self.country.upper()}\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        # Solar potential metrics\n",
    "        print(\"1. SOLAR POTENTIAL METRICS\")\n",
    "        print(\"-\" * 70)\n",
    "        print(f\"   Average GHI: {self.df_clean['GHI'].mean():.2f} W/m²\")\n",
    "        print(f\"   Peak GHI: {self.df_clean['GHI'].max():.2f} W/m²\")\n",
    "        print(f\"   Average DNI: {self.df_clean['DNI'].mean():.2f} W/m²\")\n",
    "        print(f\"   Average DHI: {self.df_clean['DHI'].mean():.2f} W/m²\")\n",
    "        print(f\"   GHI Variability (Std Dev): {self.df_clean['GHI'].std():.2f} W/m²\")\n",
    "        \n",
    "        # Environmental conditions\n",
    "        print(f\"\\n2. ENVIRONMENTAL CONDITIONS\")\n",
    "        print(\"-\" * 70)\n",
    "        print(f\"   Average Temperature: {self.df_clean['Tamb'].mean():.2f} °C\")\n",
    "        print(f\"   Average Humidity: {self.df_clean['RH'].mean():.2f} %\")\n",
    "        print(f\"   Average Wind Speed: {self.df_clean['WS'].mean():.2f} m/s\")\n",
    "        print(f\"   Average Pressure: {self.df_clean['BP'].mean():.2f} hPa\")\n",
    "        \n",
    "        # Module performance\n",
    "        if 'ModA' in self.df_clean.columns and 'ModB' in self.df_clean.columns:\n",
    "            print(f\"\\n3. MODULE PERFORMANCE\")\n",
    "            print(\"-\" * 70)\n",
    "            print(f\"   Average ModA: {self.df_clean['ModA'].mean():.2f} W/m²\")\n",
    "            print(f\"   Average ModB: {self.df_clean['ModB'].mean():.2f} W/m²\")\n",
    "            \n",
    "            # Module temperature impact\n",
    "            if 'TModA' in self.df_clean.columns:\n",
    "                print(f\"   Average Module Temp A: {self.df_clean['TModA'].mean():.2f} °C\")\n",
    "            if 'TModB' in self.df_clean.columns:\n",
    "                print(f\"   Average Module Temp B: {self.df_clean['TModB'].mean():.2f} °C\")\n",
    "        \n",
    "        # Temporal patterns\n",
    "        print(f\"\\n4. TEMPORAL PATTERNS\")\n",
    "        print(\"-\" * 70)\n",
    "        peak_hour = self.df_clean.groupby('Hour')['GHI'].mean().idxmax()\n",
    "        peak_month = self.df_clean.groupby('Month')['GHI'].mean().idxmax()\n",
    "        print(f\"   Peak Solar Hour: {peak_hour}:00\")\n",
    "        print(f\"   Peak Solar Month: {peak_month}\")\n",
    "        \n",
    "        # Data quality\n",
    "        print(f\"\\n5. DATA QUALITY SCORE\")\n",
    "        print(\"-\" * 70)\n",
    "        completeness = (1 - self.df.isna().sum().sum() / (self.df.shape[0] * self.df.shape[1])) * 100\n",
    "        print(f\"   Data Completeness: {completeness:.2f}%\")\n",
    "        \n",
    "        print(f\"\\n{'='*70}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
